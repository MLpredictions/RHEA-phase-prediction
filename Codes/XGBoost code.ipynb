{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ONUBBSWx3f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/dataset.csv'  # Adjust the path as needed\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop non-numeric columns and separate features and target variable\n",
        "# Replace problematic values and convert columns to numeric\n",
        "def safe_convert_to_numeric(series):\n",
        "    return pd.to_numeric(series, errors='coerce')  # Coerce invalid strings to NaN\n",
        "\n",
        "X = data.drop(columns=['HEA combinations', 'Phases', 'Unnamed: 20'], errors='ignore')  # Drop specified columns\n",
        "X = X.apply(safe_convert_to_numeric)  # Convert all columns to numeric\n",
        "y = data['Phases']  # Target variable\n",
        "\n",
        "# Relabel target values to sequential integers\n",
        "y_mapped, unique_labels = pd.factorize(y)\n",
        "\n",
        "# Impute missing values with the mean of each column\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_mapped, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the XGBoost model with hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],           # Number of trees\n",
        "    'max_depth': [3, 5, 7],                  # Maximum depth of each tree\n",
        "    'learning_rate': [0.01, 0.1, 0.2],       # Learning rate\n",
        "    'subsample': [0.8, 1.0],                 # Fraction of samples used per tree\n",
        "    'colsample_bytree': [0.8, 1.0]           # Fraction of features used per tree\n",
        "}\n",
        "\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and parameters\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_xgb, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=unique_labels, yticklabels=unique_labels)\n",
        "plt.title('Confusion Matrix - XGBoost')\n",
        "plt.xlabel('Predicted Phases')\n",
        "plt.ylabel('True Phases')\n",
        "plt.show()\n",
        "\n",
        "# Print accuracy score\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f'XGBoost Accuracy: {accuracy_xgb:.2f}')\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=unique_labels))\n"
      ]
    }
  ]
}